{"cells":[{"cell_type":"markdown","metadata":{"id":"k4ezJirofDOK"},"source":["# Ejercicion de programación - Regresión Logistica\n","\n","En este ejercicio se implementa regresion logistica y se aplica a dos diferentes datasets."]},{"cell_type":"code","execution_count":null,"metadata":{"id":"TXCbVxPQhvDO"},"outputs":[],"source":["# LABORATORIO 3 REGRESION LOGISTICA, CLASIFICACION BINARIA\n","# MIRANDA GUTIERREZ CESAR ALVARO\n","# Logisticregression telecomCustomer churmprediction\n","# https://www.kaggle.com/datasets/dileep070/logisticregression-telecomcustomer-churmprediction\n","# Buscar un dataset para regresión logística, que contenga al menos 7 propiedades (n>=7) y por lo menos 1000 ejemplos (m>1000), para entrenar el modelo con este dataset,\n","# y realizar las respectivas predicciones que demuestren la efectividad del mismo. Se debe subir los cuadernillos modificados, el dataset y todo aquello que considere necesario para completar con el ejercicio.\n","# Cada estudiante debe elegir un dataset diferente, para coordinar esto, se debe registrar el dataset elegido con la auxiliar de docencia (Daniela).\n","# Para la lectura, normalizacion y otras operaciones de preparacion del dataset se debe utilizar obligatoriamente la libreria pandas.\n","# Es impresindible demostrar la efectividad del modelo, considerando un porcentaje del 80% del total de los datos para entrenamiento y el 20% del total como datos de prueba,\n","# con los cuales se debe demostrar el error producido en ambos grupos y la respectiva efectividad. Para le proprocesado del dataset, se debe utilizar Pandas.\n","import os\n","import numpy as np\n","from matplotlib import pyplot\n","# Modulo de optimización de scipy\n","from scipy import optimize\n","# Necesario para graficar superficies\n","from mpl_toolkits.mplot3d import Axes3D\n","# llama a matplotlib a embeber graficas dentro de los cuadernillos\n","%matplotlib inline"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"hsQaGJOmfbi5"},"outputs":[],"source":["# serie de comandos de shell que se pueden ejecutar en una interfaz de Python como IPython.\n","# !ls: lista los archivos y directorios del directorio actual.\n","# %mkdir data: crea un directorio llamado data en el directorio actual1. El signo % indica que se trata\n","# de un comando mágico de IPython, que son funciones especiales que proporcionan funcionalidades adicionales\n","# !ls: lista los archivos y directorios del directorio actual de nuevo, mostrando el nuevo directorio data creado"]},{"cell_type":"code","source":["!ls\n","%mkdir data\n","!ls"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"i9ae3yaqpuu7","executionInfo":{"status":"ok","timestamp":1694402864032,"user_tz":240,"elapsed":405,"user":{"displayName":"Cesar Alvaro Miranda Gutierrez","userId":"02602926099808201823"}},"outputId":"a010bb39-75b8-4881-d92a-ee793ff9af89"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["data  drive  sample_data\n","mkdir: cannot create directory ‘data’: File exists\n","data  drive  sample_data\n"]}]},{"cell_type":"code","execution_count":null,"metadata":{"id":"FQ36O7gLiEBS"},"outputs":[],"source":["#importa pandas, es una biblioteca para manipular datos\n","import pandas as pd\n","#encoder para transformar etiquetas categoricas a numericas\n","from sklearn.preprocessing import LabelEncoder\n","#import datetime for working with dates and times.\n","from datetime import datetime"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":2593,"status":"ok","timestamp":1694402876213,"user":{"displayName":"Cesar Alvaro Miranda Gutierrez","userId":"02602926099808201823"},"user_tz":240},"id":"huAdlrqgj_xP","outputId":"ac7d9894-e3e1-4ddf-e728-f1e0a1ecc0d9"},"outputs":[{"output_type":"stream","name":"stdout","text":["Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"]}],"source":["# usa el módulo google.colab para acceder a Google Drive desde Colaboratory.\n","from google.colab import drive\n","# Usa la función drive.mount(path) para montar tu Google Drive como un sistema de archivos local en el directorio especificado por el argumento path\n","drive.mount('/content/drive')"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":36},"executionInfo":{"elapsed":346,"status":"ok","timestamp":1694402878014,"user":{"displayName":"Cesar Alvaro Miranda Gutierrez","userId":"02602926099808201823"},"user_tz":240},"id":"uafc5vSkfL9X","outputId":"dd5b625e-2c01-44d7-dd1e-2b80395c5956"},"outputs":[{"output_type":"execute_result","data":{"text/plain":["'/content/data/churn_data.csv'"],"application/vnd.google.colaboratory.intrinsic+json":{"type":"string"}},"metadata":{},"execution_count":94}],"source":["# Carga de dataset\n","# import pandas as pd\n","# data = pd.read_csv('/content/pima-indians-diabetes.csv')\n","# Importa el módulo shutil\n","import shutil\n","# Usa la función shutil.copy(src, dst) para copiar el contenido del archivo src al archivo o directorio dst\n","# El primer argumento es una cadena que representa la ruta del archivo fuente, y el segundo argumento es una cadena que representa la ruta del archivo o directorio destino.\n","# La función shutil.copy(src, dst) devuelve una cadena que representa la ruta del nuevo archivo creado.\n","shutil.copy(\"/content/drive/MyDrive/SIS420/Laboratorios/Laboratorio3/churn_data.csv\",\"/content/data/churn_data.csv\")"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"ohR9xAR2j-MC"},"outputs":[],"source":["# Cargar datos\n","# Las dos primeras columnas contienen la nota de dos examenes y la tercera columna\n","# contiene la etiqueta que indica si el alumno ingreso o no a la universidad.\n","# data = np.loadtxt(os.path.join('data', 'churn_data.csv'), delimiter=',', skiprows=1)\n","# df, que contiene el DataFrame con los datos del archivo CSV.\n","df = pd.read_csv(os.path.join('data', 'churn_data.csv'), delimiter=',')\n","# convertir el DataFrame en un arreglo de NumPy.\n","data = df.to_numpy()"]},{"cell_type":"code","source":["print(data)\n","data.shape"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"uLJKvqrv1Jbs","executionInfo":{"status":"ok","timestamp":1694402884034,"user_tz":240,"elapsed":485,"user":{"displayName":"Cesar Alvaro Miranda Gutierrez","userId":"02602926099808201823"}},"outputId":"fbf38e5d-ad6b-41d1-87f1-4f5c5ccbc03d"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["[['7590-VHVEG' 1 'No' ... 29.85 '29.85' 'No']\n"," ['5575-GNVDE' 34 'Yes' ... 56.95 '1889.5' 'No']\n"," ['3668-QPYBK' 2 'Yes' ... 53.85 '108.15' 'Yes']\n"," ...\n"," ['2234-XADUH' 72 'Yes' ... 103.2 '7362.9' 'No']\n"," ['4801-JZAZL' 11 'No' ... 29.6 '346.45' 'No']\n"," ['8361-LTMKD' 4 'Yes' ... 74.4 '306.6' 'Yes']]\n"]},{"output_type":"execute_result","data":{"text/plain":["(7042, 9)"]},"metadata":{},"execution_count":96}]},{"cell_type":"code","execution_count":null,"metadata":{"id":"HYJDzENEiaIj"},"outputs":[],"source":["# def plotData(X, y):\n","#     # Gragica los puntos de datos X y y en una nueva figura. Grafica los puntos de datos con * para los positivos y\n","#     # o para los negativos.\n","\n","#     # Crea una nueva figura\n","#     fig = pyplot.figure()\n","\n","#     # Find Indices of Positive and Negative Examples\n","#     pos = y == 1\n","#     neg = y == 0\n","\n","#     # Plot Examples\n","#     pyplot.plot(X[pos, 0], X[pos, 1], 'k*', lw=2, ms=10)\n","#     pyplot.plot(X[neg, 0], X[neg, 1], 'ko', mfc='y', ms=8, mec='k', mew=1)"]},{"cell_type":"code","source":["#CONVERTIR VARIABLES CATEGORICAS A ENTEROS (no modificar)\n","#variables categoricas, contiene las listas de las columnas de data que tienen tipo de dato object.\n","data = pd.DataFrame(data) # convierte la matriz de numpy en un DataFrame de pandas\n","columnas_categoricas = data.select_dtypes(include=['object']).columns\n","for columna in columnas_categoricas:\n","  #usa labelencoder para crear objeto llamado le, que permite transformar valores categoricos a enteros.\n","  le = LabelEncoder()\n","  # usa lift_transform del objeto le para ajustar el codificador a los valores de la columna y devolver una serie d enumero enteros\n","  data[columna] = le.fit_transform(data[columna])\n","data.info()"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"4Pc32JTqFHJn","executionInfo":{"status":"ok","timestamp":1694402890336,"user_tz":240,"elapsed":490,"user":{"displayName":"Cesar Alvaro Miranda Gutierrez","userId":"02602926099808201823"}},"outputId":"5a179cb6-9311-485f-cc12-8d62fac554a5"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["<class 'pandas.core.frame.DataFrame'>\n","RangeIndex: 7042 entries, 0 to 7041\n","Data columns (total 9 columns):\n"," #   Column  Non-Null Count  Dtype\n","---  ------  --------------  -----\n"," 0   0       7042 non-null   int64\n"," 1   1       7042 non-null   int64\n"," 2   2       7042 non-null   int64\n"," 3   3       7042 non-null   int64\n"," 4   4       7042 non-null   int64\n"," 5   5       7042 non-null   int64\n"," 6   6       7042 non-null   int64\n"," 7   7       7042 non-null   int64\n"," 8   8       7042 non-null   int64\n","dtypes: int64(9)\n","memory usage: 495.3 KB\n"]}]},{"cell_type":"code","source":["print(data)\n","data.shape"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"ZmlEe9ciGyul","executionInfo":{"status":"ok","timestamp":1694402896717,"user_tz":240,"elapsed":405,"user":{"displayName":"Cesar Alvaro Miranda Gutierrez","userId":"02602926099808201823"}},"outputId":"fbade56e-7553-48c7-9823-c47207565ca1"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["         0   1  2  3  4  5     6     7  8\n","0     5374   1  0  0  1  2   142  2505  0\n","1     3961  34  1  1  0  3   498  1466  0\n","2     2563   2  1  0  1  3   436   157  1\n","3     5534  45  0  1  0  0   266  1400  0\n","4     6510   2  1  0  1  2   729   925  1\n","...    ...  .. .. .. .. ..   ...   ... ..\n","7037  1758  72  1  2  1  0    52   770  0\n","7038  4852  24  1  1  1  3   991  1597  0\n","7039  1525  72  1  1  1  1  1340  5697  0\n","7040  3366  11  0  0  1  2   137  2994  0\n","7041  5933   4  1  0  1  3   795  2660  1\n","\n","[7042 rows x 9 columns]\n"]},{"output_type":"execute_result","data":{"text/plain":["(7042, 9)"]},"metadata":{},"execution_count":98}]},{"cell_type":"code","source":["X, y = np.take(data, [0, 1, 2, 3, 4, 5, 6, 7], axis=1), np.take(data, [8], axis=1) # usa el método np.take para seleccionar las columnas 0 a 7 como X y la columna 8 como y print(X) print(y)\n","y = np.ravel(y) # usa el método np.ravel para convertir tu arreglo bidimensional en unidimensional\n","print(X)\n","print(y) # imprime la forma de tu nuevo arreglo"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"VGixwaZoHctw","executionInfo":{"status":"ok","timestamp":1694402904416,"user_tz":240,"elapsed":411,"user":{"displayName":"Cesar Alvaro Miranda Gutierrez","userId":"02602926099808201823"}},"outputId":"0b1f9a67-4373-47df-bac2-ac2b19e68359"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["         0   1  2  3  4  5     6     7\n","0     5374   1  0  0  1  2   142  2505\n","1     3961  34  1  1  0  3   498  1466\n","2     2563   2  1  0  1  3   436   157\n","3     5534  45  0  1  0  0   266  1400\n","4     6510   2  1  0  1  2   729   925\n","...    ...  .. .. .. .. ..   ...   ...\n","7037  1758  72  1  2  1  0    52   770\n","7038  4852  24  1  1  1  3   991  1597\n","7039  1525  72  1  1  1  1  1340  5697\n","7040  3366  11  0  0  1  2   137  2994\n","7041  5933   4  1  0  1  3   795  2660\n","\n","[7042 rows x 8 columns]\n","[0 0 1 ... 0 0 1]\n"]}]},{"cell_type":"markdown","metadata":{"id":"VFzWxw7SfDON"},"source":["## 1 Regresion Logistica\n","\n","En esta parte del ejercicio, creará un modelo de regresión logística para predecir si un estudiante será admitido en una universidad. Suponga que es el administrador de un departamento universitario y desea determinar las posibilidades de admisión de cada solicitante en función de sus resultados en dos exámenes. Tiene datos históricos de solicitantes anteriores que puede usar como un conjunto de capacitación para la regresión logística. Para cada ejemplo de capacitación, se tiene las calificaciones del solicitante en dos exámenes y la decisión de admisión. Su tarea es crear un modelo de clasificación que calcule la probabilidad de admisión de un solicitante en función de los puntajes de esos dos exámenes.\n","\n","La siguiente celda cargará los datos y las etiquetas correspondientes:"]},{"cell_type":"markdown","metadata":{"id":"8ApVCPJ1fDOO"},"source":["### 1.1 Visualizar los datos\n","\n","Antes de comenzar a implementar cualquier algoritmo de aprendizaje, siempre es bueno visualizar los datos si es posible. Mostramos los datos en una gráfica bidimensional llamando a la función `plotData`. Se completará el código en `plotData` para que muestre una figura donde los ejes son los dos puntajes de los dos examenes, los ejemplos positivos y negativos se muestran con diferentes marcadores."]},{"cell_type":"markdown","metadata":{"id":"dnilg8q4fDOP"},"source":["Se llama a la función implementada para mostrar los datos cargados:"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"Z8zAR-pwfDOP"},"outputs":[],"source":["# plotData(X, y)\n","# # adiciona etiquetas para los ejes\n","# pyplot.xlabel('Calificación Examen 1')\n","# pyplot.ylabel('Calificación Examen 2')\n","# pyplot.legend(['Admitido', 'No admitido'])\n","# pass"]},{"cell_type":"markdown","metadata":{"id":"z-Xx5IVBfDOP"},"source":["<a id=\"section1\"></a>\n","### 1.2 Implementacion\n","\n","#### 1.2.1 Fución Sigmoidea\n","\n","La hipotesis para la regresión logistica se define como:\n","\n","$$ h_\\theta(x) = g(\\theta^T x)$$\n","\n","donde la función $g$ is la función sigmoidea. La función sigmoidea se define como:\n","\n","$$g(z) = \\frac{1}{1+e^{-z}}$$.\n","\n","Los resultados que debe generar la funcion sigmoidea para valores positivos amplios de `x`, deben ser cercanos a 1, mientras que para valores negativos grandes, la sigmoide debe generar valores cercanos 0. La evaluacion de `sigmoid(0)` debe dar un resultado exacto de 0.5. Esta funcion tambien debe poder trabajar con vectores y matrices."]},{"cell_type":"code","execution_count":null,"metadata":{"id":"Yxz27db7fDOQ"},"outputs":[],"source":["def sigmoid(z):\n","    # Calcula la sigmoide de una entrada z\n","    # convierte la intrada a un arreglo numpy\n","    z = np.array(z)\n","\n","    g = np.zeros(z.shape)\n","\n","    g = 1 / (1 + np.exp(-z))\n","\n","    return g"]},{"cell_type":"markdown","metadata":{"id":"kzXMjefFfDOQ"},"source":["Se calcula el valor de la sigmoide aplicando la funcion sigmoid con `z=0`, se debe obtener un resultado de 0.5. RE recomienda experimentar con otros valores de `z`."]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":2,"status":"ok","timestamp":1694402920017,"user":{"displayName":"Cesar Alvaro Miranda Gutierrez","userId":"02602926099808201823"},"user_tz":240},"id":"arfKRAAVfDOQ","outputId":"00362b67-ad56-4a32-b99e-62aafec4fa64"},"outputs":[{"output_type":"stream","name":"stdout","text":["g( 0 ) =  0.5\n"]}],"source":["# Prueba la implementacion de la funcion sigmoid\n","z = 0\n","g = sigmoid(z)\n","\n","print('g(', z, ') = ', g)"]},{"cell_type":"markdown","metadata":{"id":"BQ9Jf06yfDOR"},"source":["<a id=\"section2\"></a>\n","#### 1.2.2 Función de Costo y Gradiente\n","\n","Se implementa la funcion cost y gradient, para la regresión logistica. Antes de continuar es importante agregar el termino de intercepcion a X."]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":407,"status":"ok","timestamp":1694402923418,"user":{"displayName":"Cesar Alvaro Miranda Gutierrez","userId":"02602926099808201823"},"user_tz":240},"id":"COMnlBxmfDOR","outputId":"56728ca7-3490-4da3-f12f-4becc1074e89"},"outputs":[{"output_type":"stream","name":"stdout","text":["[1.000e+00 6.550e+03 8.000e+00 1.000e+00 0.000e+00 1.000e+00 2.000e+00\n"," 1.274e+03 6.103e+03]\n"]}],"source":["# Configurar la matriz adecuadamente, y agregar una columna de unos que corresponde al termino de intercepción.\n","m, n = X.shape\n","# Agraga el termino de intercepción a A\n","X = np.concatenate([np.ones((m, 1)), X], axis=1)\n","print(X[5])"]},{"cell_type":"markdown","metadata":{"id":"fO9hT_XbfDOS"},"source":["La funcion de costo en una regresión logistica es:\n","\n","$$ J(\\theta) = \\frac{1}{m} \\sum_{i=1}^{m} \\left[ -y^{(i)} \\log\\left(h_\\theta\\left( x^{(i)} \\right) \\right) - \\left( 1 - y^{(i)}\\right) \\log \\left( 1 - h_\\theta\\left( x^{(i)} \\right) \\right) \\right]$$\n","\n","y el gradiente del costo es un vector de la misma longitud como $\\theta$ donde el elemento $j^{th}$ (para $j = 0, 1, \\cdots , n$) se define como:\n","\n","$$ \\frac{\\partial J(\\theta)}{\\partial \\theta_j} = \\frac{1}{m} \\sum_{i=1}^m \\left( h_\\theta \\left( x^{(i)} \\right) - y^{(i)} \\right) x_j^{(i)} $$\n","\n","Si bien este gradiente parece idéntico al gradiente de regresión lineal, la fórmula es diferente porque la regresión lineal y logística tienen diferentes definiciones de $h_\\theta(x)$.\n","<a id=\"costFunction\"></a>"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"Cu1DP0y0fDOT"},"outputs":[],"source":["def calcularCosto(theta, X, y):\n","    # Inicializar algunos valores utiles\n","    m = y.size  # numero de ejemplos de entrenamiento\n","\n","    J = 0\n","    h = sigmoid(X.dot(theta.T))\n","    J = (1 / m) * np.sum(-y.dot(np.log(h)) - (1 - y).dot(np.log(1 - h)))\n","\n","    return J"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"BZhegpMZfDOT"},"outputs":[],"source":["def descensoGradiente(theta, X, y, alpha, num_iters):\n","    # Inicializa algunos valores\n","    m = y.shape[0] # numero de ejemplos de entrenamiento\n","\n","    # realiza una copia de theta, el cual será acutalizada por el descenso por el gradiente\n","    theta = theta.copy()\n","    J_history = []\n","\n","    for i in range(num_iters):\n","        h = sigmoid(X.dot(theta.T))\n","        theta = theta - (alpha / m) * (h - y).dot(X)\n","\n","        J_history.append(calcularCosto(theta, X, y))\n","    return theta, J_history"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":357,"status":"ok","timestamp":1694403625644,"user":{"displayName":"Cesar Alvaro Miranda Gutierrez","userId":"02602926099808201823"},"user_tz":240},"id":"SWXIkeQafDOT","outputId":"fc64149d-ee3e-4df0-81c4-7a0def77a810","scrolled":true},"outputs":[{"output_type":"execute_result","data":{"text/plain":["(7042, 9)"]},"metadata":{},"execution_count":112}],"source":["# Elegir algun valor para alpha (probar varias alternativas)\n","alpha = 0.0001\n","num_iters = 100\n","\n","# inicializa theta y ejecuta el descenso por el gradiente\n","theta = np.zeros(9)\n","X.shape"]},{"cell_type":"code","source":["y.shape"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"MuYiY_g7OWmu","executionInfo":{"status":"ok","timestamp":1694402941288,"user_tz":240,"elapsed":346,"user":{"displayName":"Cesar Alvaro Miranda Gutierrez","userId":"02602926099808201823"}},"outputId":"b2a513a6-0f22-4402-b8a3-7b6ed47aebb7"},"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["(7042,)"]},"metadata":{},"execution_count":106}]},{"cell_type":"code","source":["theta.shape"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"BylHscDlOY99","executionInfo":{"status":"ok","timestamp":1694402943676,"user_tz":240,"elapsed":322,"user":{"displayName":"Cesar Alvaro Miranda Gutierrez","userId":"02602926099808201823"}},"outputId":"40abd813-10d6-42ff-eb96-bfe852f609b0"},"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["(9,)"]},"metadata":{},"execution_count":107}]},{"cell_type":"code","source":["theta, J_history = descensoGradiente(theta, X, y, alpha, num_iters)\n","\n","# Grafica la convergencia del costo\n","pyplot.plot(np.arange(len(J_history)), J_history, lw=2)\n","pyplot.xlabel('Numero de iteraciones')\n","pyplot.ylabel('Costo J')\n","\n","# Muestra los resultados del descenso por el gradiente\n","print('theta calculado por el descenso por el gradiente: {:s}'.format(str(theta)))\n","\n","# verificar si ingresa o no a la universidad\n","X_array = [1, 10, 10,1, 10, 10,1, 10, 10]\n","aprueba = sigmoid(np.dot(X_array, theta))   # Se debe cambiar esto\n","\n","print(f\"Un estudiante con nota del examen 1: {X_array[1]} y nota del examen 2: {X_array[2]} (usando el descenso por el gradiente):{aprueba}\")"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":615},"id":"2DcNLJ7vORJ2","executionInfo":{"status":"ok","timestamp":1694403636306,"user_tz":240,"elapsed":917,"user":{"displayName":"Cesar Alvaro Miranda Gutierrez","userId":"02602926099808201823"}},"outputId":"aa33f972-3d62-4278-8afe-4482c2f33f09"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stderr","text":["<ipython-input-100-22f640bc02db>:8: RuntimeWarning: overflow encountered in exp\n","  g = 1 / (1 + np.exp(-z))\n","<ipython-input-103-9bf1ce321844>:7: RuntimeWarning: divide by zero encountered in log\n","  J = (1 / m) * np.sum(-y.dot(np.log(h)) - (1 - y).dot(np.log(1 - h)))\n"]},{"output_type":"stream","name":"stdout","text":["theta calculado por el descenso por el gradiente: [-1.38773917e-04 -1.35052103e-01 -4.25906654e-02 -1.32439024e-04\n"," -1.49329453e-03  2.90216113e-04  3.16396890e-04  1.76893204e-01\n"," -1.32650106e-01]\n","Un estudiante con nota del examen 1: 10 y nota del examen 2: 10 (usando el descenso por el gradiente):0.20652799148873027\n"]},{"output_type":"display_data","data":{"text/plain":["<Figure size 640x480 with 1 Axes>"],"image/png":"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\n"},"metadata":{}}]},{"cell_type":"code","execution_count":null,"metadata":{"id":"SVHZbgOZfDOU"},"outputs":[],"source":["def costFunction(theta, X, y):\n","    # Inicializar algunos valores utiles\n","    m = y.size  # numero de ejemplos de entrenamiento\n","\n","    J = 0\n","    grad = np.zeros(theta.shape)\n","\n","    h = sigmoid(X.dot(theta.T))\n","\n","    J = (1 / m) * np.sum(-y.dot(np.log(h)) - (1 - y).dot(np.log(1 - h)))\n","    grad = (1 / m) * (h - y).dot(X)\n","\n","    return J, grad"]},{"cell_type":"markdown","metadata":{"id":"2i_6-QS7fDOU"},"source":["Se prueba la funcion `costFunction` utilizando dos casos de prueba para $\\theta$."]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"KCq2CXdWfDOU","outputId":"f8ca3fa4-9a0d-4095-d0e3-c212cb15ea0f","executionInfo":{"status":"ok","timestamp":1694404709175,"user_tz":240,"elapsed":350,"user":{"displayName":"Cesar Alvaro Miranda Gutierrez","userId":"02602926099808201823"}}},"outputs":[{"output_type":"stream","name":"stdout","text":["[0. 0. 0. 0. 0. 0. 0. 0. 0.]\n","theta inicial (zeros): 0.693\n","[2.34592445e-01 8.41594646e+02 1.14113888e+01 2.10309571e-01\n"," 3.07938086e-01 9.72735018e-02 3.18943482e-01 1.21522792e+02\n"," 7.51996947e+02]\n","Gradiente en theta inicial (zeros):\n","\t[0.2346, 841.5946, 11.4114]\n"]}],"source":["# Inicializacion de parametros de ajuste\n","initial_theta = np.zeros(n+1)\n","print(initial_theta)\n","cost, grad = costFunction(initial_theta, X, y)\n","\n","print('theta inicial (zeros): {:.3f}'.format(cost))\n","# print('Costo esperado (aproximado): 0.693\\n')\n","print(grad)\n","print('Gradiente en theta inicial (zeros):')\n","print('\\t[{:.4f}, {:.4f}, {:.4f}]'.format(*grad))\n","# print('Gradiente esperado (aproximado):\\n\\t[-0.1000, -12.0092, -11.2628]\\n')\n","\n"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"ShafqjdBfDOU","outputId":"244bb83f-14a8-4496-8836-2c9d8cd2f70c","executionInfo":{"status":"ok","timestamp":1694403793907,"user_tz":240,"elapsed":342,"user":{"displayName":"Cesar Alvaro Miranda Gutierrez","userId":"02602926099808201823"}}},"outputs":[{"output_type":"stream","name":"stdout","text":["[-24.    0.2   0.2 -24.    0.2   0.2 -24.    0.2   0.2]\n","Costo en theta prueba: nan\n","Costo esperado (aproximado): 0.218\n","\n","Gradiente en theta prueba:\n","\t[0.734, 2601.709, 27.566]\n","Gradiente esperado (aproximado):\n","\t[0.043, 2.566, 2.647]\n"]},{"output_type":"stream","name":"stderr","text":["<ipython-input-109-e3041c0335d8>:10: RuntimeWarning: divide by zero encountered in log\n","  J = (1 / m) * np.sum(-y.dot(np.log(h)) - (1 - y).dot(np.log(1 - h)))\n"]}],"source":["\n","test_theta = np.array([-24, 0.2, 0.2,-24, 0.2, 0.2,-24, 0.2, 0.2])\n","print(test_theta)\n","cost, grad = costFunction(test_theta, X, y)\n","\n","print('Costo en theta prueba: {:.3f}'.format(cost))\n","print('Costo esperado (aproximado): 0.218\\n')\n","\n","print('Gradiente en theta prueba:')\n","print('\\t[{:.3f}, {:.3f}, {:.3f}]'.format(*grad))\n","# print('Gradiente esperado (aproximado):\\n\\t[0.043, 2.566, 2.647]')"]},{"cell_type":"markdown","metadata":{"id":"IL6NtnvDfDOV"},"source":["#### 1.2.3 Parámetros de aprendizaje usando `scipy.optimize`\n","\n","En el codigo anterior se encontró los parámetros óptimos de un modelo de regresión lineal al implementar el descenso de gradiente. Se implemento una función de costo y se calculó su gradiente, utilizando el algoritmo del descenso por el gradiente.\n","\n","En lugar de realizar los pasos del descenso por el gradiente, se utilizará el [módulo `scipy.optimize`] (https://docs.scipy.org/doc/scipy/reference/optimize.html). SciPy es una biblioteca de computación numérica para `python`. Proporciona un módulo de optimización para la búsqueda y minimización de raíces. A partir de `scipy 1.0`, la función` scipy.optimize.minimize` es el método a utilizar para problemas de optimización (tanto restringidos como no restringidos).\n","\n","For logistic regression, you want to optimize the cost function $J(\\theta)$ with parameters $\\theta$.\n","Concretely, you are going to use `optimize.minimize` to find the best parameters $\\theta$ for the logistic regression cost function, given a fixed dataset (of X and y values). You will pass to `optimize.minimize` the following inputs:\n","\n","Para la regresión logística, se desea optimizar la función de costo $J(\\theta)$ con los parámetros $\\theta$.\n","Concretamente, se va a utilizar `optimize.minimize` para encontrar los mejores parámetros $\\theta$ para la función de costo de regresión logística, dado un dataset fijo (de valores X e y). Se pasara a `optimize.minimize` las siguientes entradas:\n","\n","- `costFunction`: Una función de costo que, cuando se le da el dataset de entrenamiento y un $\\theta$ particular, calcula el costo de regresión logística y el gradiente con respecto a $\\theta$ para el dataset(X, y). Es importante tener en cuenta que solo se pasa el nombre de la función sin el paréntesis. Esto indica que solo proporcionamos una referencia a esta función y no evaluamos el resultado de esta función.\n","- `initial_theta`: Los valores iniciales de los parametros que se tratan de optimizar.\n","- `(X, y)`: Estos son argumentos adicionales a la funcion de costo.\n","- `jac`: Indicación si la función de costo devuelve el jacobiano (gradiente) junto con el valor de costo. (True)\n","- `method`: Método / algoritmo de optimización a utilizar\n","- `options`: Opciones adicionales que pueden ser específicas del método de optimización específico. Solo se indica al algoritmo el número máximo de iteraciones antes de que termine.\n","\n","Si se ha completado la `costFunction` correctamente,`optimize.minimize` convergerá en los parámetros de optimización correctos y devolverá los valores finales del costo y $\\theta$ en un objeto de clase.\n","\n","Al usar `optimize.minimize`, no se tuvo que escribir ningún bucle ni establecer una tasa de aprendizaje como se hizo para el descenso de gradientes. Todo esto se hace mediante `optimize.minimize`: solo se necesita proporcionar una función que calcule el costo y el gradiente.\n","\n","A continuación, se tiene el código para llamar a `optimize.minimize` con los argumentos correctos."]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"xBuAfC8zfDOV","outputId":"b73844fa-c399-4dad-fcaf-9563ce911df8","scrolled":true,"executionInfo":{"status":"ok","timestamp":1694403801051,"user_tz":240,"elapsed":343,"user":{"displayName":"Cesar Alvaro Miranda Gutierrez","userId":"02602926099808201823"}}},"outputs":[{"output_type":"stream","name":"stdout","text":["Costo con un valor de theta encontrado por optimize.minimize: 0.427\n","Costo esperado (aproximado): 0.203\n","\n","theta:\n","\t[-0.646, -0.000, -0.039]\n","Theta esperado (aproximado):\n","\t[-25.161, 0.206, 0.201]\n"]},{"output_type":"stream","name":"stderr","text":["<ipython-input-115-0dfcfa2e2ef1>:7: DeprecationWarning: 'maxiter' has been deprecated in favor of 'maxfun' and will be removed in SciPy 1.11.0.\n","  res = optimize.minimize(costFunction,\n"]}],"source":["# Establecer las opciones para optimize.minimize\n","options= {'maxiter': 1000}\n","\n","# revisar la documentacion de scipy's optimize.minimize para mayor descripcion de los parametros\n","# La funcion devuekve un objeto `OptimizeResult`\n","# Se utiliza el algoritmo de Newton truncado para la optimización.\n","res = optimize.minimize(costFunction,\n","                        initial_theta,\n","                        (X, y),\n","                        jac=True,\n","                        method='TNC',\n","                        options=options)\n","\n","# la propiedad fun del objeto devuelto por `OptimizeResult`\n","# contiene el valor del costFunction de un theta optimizado\n","cost = res.fun\n","\n","# Theta optimizada esta en la propiedad x\n","theta = res.x\n","\n","# Imprimir theta en la pantalla\n","print('Costo con un valor de theta encontrado por optimize.minimize: {:.3f}'.format(cost))\n","print('Costo esperado (aproximado): 0.203\\n');\n","\n","print('theta:')\n","print('\\t[{:.3f}, {:.3f}, {:.3f}]'.format(*theta))\n","# print('Theta esperado (aproximado):\\n\\t[-25.161, 0.206, 0.201]')"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"gi59sTcYU9py","outputId":"0dc14d53-8bba-448c-b447-bf8dc0a8a6e7","executionInfo":{"status":"ok","timestamp":1694405007939,"user_tz":240,"elapsed":384,"user":{"displayName":"Cesar Alvaro Miranda Gutierrez","userId":"02602926099808201823"}}},"outputs":[{"output_type":"stream","name":"stdout","text":["Una persona con los siguientte parametros: 90 y los siguientes: 70 (usando el descenso por el gradiente):0.9999999998028388\n"]}],"source":["# verificar si nos da un 0 o un 1\n","X_array = [1, 90, 70,1, 90, 70,1, 90, 70]\n","theta_om = [-25.161, 0.206, 0.201,-25.161, 0.206, 0.201,-25.161, 0.206, 0.201]\n","aprueba = sigmoid(np.dot(X_array, theta_om))   # Se debe cambiar esto\n","\n","print(f\"Una persona con los siguientte parametros: {X_array[1]} y los siguientes: {X_array[2]} (usando el descenso por el gradiente):{aprueba}\")"]},{"cell_type":"markdown","metadata":{"id":"HG7T_XtNfDOW"},"source":["Una vez que se completa `optimize.minimize`, se usa el valor final de $\\theta$ para visualizar el límite de decisión en los datos de entrenamiento.\n","\n","Para hacerlo, se implementa la función `plotDecisionBoundary` para trazar el límite de decisión sobre los datos de entrenamiento."]},{"cell_type":"code","execution_count":null,"metadata":{"id":"pLP6foKzfDOW"},"outputs":[],"source":["def plotDecisionBoundary(plotData, theta, X, y):\n","    \"\"\"\n","    Grafica los puntos X y Y en una nueva figura con un limite de desicion definido por theta.\n","    the data points X and y into a new figure with the decision boundary defined by theta.\n","    Grafica los puntos con * para los ejemplos positivos y con o para los ejemplos negativos.\n","\n","    Parametros:\n","    ----------\n","    plotData : func\n","        A function reference for plotting the X, y data.\n","\n","    theta : array_like\n","        Parametros para la regresion logistica. Un vecto de la forma (n+1, ).\n","\n","    X : array_like\n","        Data set de entrada. Se supone que X es una de las siguientes:\n","            1) Matriz Mx3, donde la primera columna es una columna de unos para intercepción.\n","            2) Matriz MxN, N> 3, donde la primera columna son todos unos.\n","\n","    y : array_like\n","        Vector de datos de etiquetas de la forma (m, ).\n","    \"\"\"\n","    # hacer que theta sera un arreglo numpy\n","    theta = np.array(theta)\n","\n","    # Graficar los datos (recordar que la primera columna en X es la intercepción)\n","    plotData(X[:, 1:3], y)\n","\n","    if X.shape[1] <= 3:\n","        # Solo se requieren 2 puntos para definir una linea, para lo cual se eligen dos puntos finales\n","        plot_x = np.array([np.min(X[:, 1]) - 2, np.max(X[:, 1]) + 2])\n","\n","        # Calcular la línea límite de decisión\n","        plot_y = (-1. / theta[2]) * (theta[1] * plot_x + theta[0])\n","\n","        print(plot_x)\n","        print(plot_y)\n","        # Graficar y ajustar los ejes para una mejor visualización\n","        pyplot.plot(plot_x, plot_y)\n","\n","        # Leyenda, especifica para el ejercicio\n","        pyplot.legend(['Admitido', 'No admitido', 'Limite de decisión'])\n","        pyplot.xlim([30, 100])\n","        pyplot.ylim([30, 100])\n","    else:\n","        # Rango de la grilla\n","        u = np.linspace(-1, 1.5, 50)\n","        v = np.linspace(-1, 1.5, 50)\n","\n","        z = np.zeros((u.size, v.size))\n","        # Evalua z = theta*x sobre la grilla\n","        for i, ui in enumerate(u):\n","            for j, vj in enumerate(v):\n","                z[i, j] = np.dot(mapFeature(ui, vj), theta)\n","\n","        z = z.T  # importante transponer z antes de llamar al contorno\n","        # print(z)\n","\n","        # Plot z = 0\n","        pyplot.contour(u, v, z, levels=[0], linewidths=2, colors='g')\n","        pyplot.contourf(u, v, z, levels=[np.min(z), 0, np.max(z)], cmap='Greens', alpha=0.4)\n"]},{"cell_type":"code","source":["# Graficar limites\n","# plotDecisionBoundary(plotData, theta, X, y)"],"metadata":{"id":"nfOM1gMtYOlm"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"jr8Lfi-ZfDOW"},"source":["<a id=\"section4\"></a>\n","#### 1.2.4 Evaluación de la regresión logistica\n","\n","Después de aprender los parámetros, se puede usar el modelo para predecir si un estudiante en particular será admitido. Para un estudiante con una puntuación en el Examen 1 de 45 y una puntuación en el Examen 2 de 85, debe esperar ver una probabilidad de admisión de 0,776. Otra forma de evaluar la calidad de los parámetros que hemos encontrado es ver qué tan bien predice el modelo aprendido en nuestro conjunto de entrenamiento."]},{"cell_type":"code","execution_count":null,"metadata":{"id":"kjavk2fEfDOX"},"outputs":[],"source":["def predict(theta, X):\n","    \"\"\"\n","    Predecir si la etiqueta es 0 o 1 mediante regresión logística aprendida.\n","    Calcula las predicciones para X usando un umbral en 0.5 (es decir, si sigmoide (theta.T * x)> = 0.5, predice 1)\n","\n","    Parametros\n","    ----------\n","    theta : array_like\n","        Parametros para regresion logistica. Un vecto de la forma (n+1, ).\n","\n","    X : array_like\n","        Datos utilizados para el calculo de las predicciones.\n","        La fila es el numero de los puntos para calcular las predicciones,\n","        y las columnas con el numero de caracteristicas.\n","\n","    Devuelve\n","    -------\n","    p : array_like\n","        Predicciones y 0 o 1 para cada fila en X.\n","    \"\"\"\n","    m = X.shape[0] # Numero de ejemplo de entrenamiento\n","\n","    p = np.zeros(m)\n","\n","    p = np.round(sigmoid(X.dot(theta.T)))\n","    return p"]},{"cell_type":"markdown","metadata":{"id":"D2rxLT_lfDOX"},"source":["Una vez entrenado el modelo se procede a realizar la prediccion y evaluación de los resultados de predecir cual es el valor que vota el modelo para todos los datos utilizados en el entrenamiento."]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"R075_m5sfDOX","outputId":"9c26de88-7027-4fc7-dc05-d568425ffe3d","executionInfo":{"status":"ok","timestamp":1694404480074,"user_tz":240,"elapsed":332,"user":{"displayName":"Cesar Alvaro Miranda Gutierrez","userId":"02602926099808201823"}}},"outputs":[{"output_type":"stream","name":"stdout","text":["Para un estudiante con notas de 45 y 85, se predice una probabilidad de admisión de: 0.000%\n","Valor esperado: 0.775 +/- 0.002\n","\n","Precisión de entrenamiento: 79.52 %\n","Precisión esperada (aproximadamente): 89.00 %\n"]}],"source":["#  Predice la probabilidad de ingreso para un estudiante con nota de 45 en el examen 1 y nota de 85 en el examen 2\n","prob = sigmoid(np.dot([1, 45, 85,1, 45, 85,1, 45, 85], theta))\n","print('Para un estudiante con notas de 45 y 85, se predice una probabilidad de admisión de: {:.3f}%'.format(prob))\n","print('Valor esperado: 0.775 +/- 0.002\\n')\n","\n","# Compute accuracy on our training set\n","p = predict(theta, X)\n","print('Precisión de entrenamiento: {:.2f} %'.format(np.mean(p == y) * 100))\n","print('Precisión esperada (aproximadamente): 89.00 %')"]}],"metadata":{"colab":{"provenance":[]},"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.8.8"}},"nbformat":4,"nbformat_minor":0}